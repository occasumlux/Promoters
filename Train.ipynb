{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ed45d4a3-c3cb-43a0-b58f-6303e6dd2f5c",
   "metadata": {},
   "source": [
    "# Model Training Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c4cd24d-1772-4944-a3f1-1dbc22dda113",
   "metadata": {},
   "source": [
    "## Imports and setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f53984-3125-4f71-8e64-4c9238aceac8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from typing import List\n",
    "from custom_models import PromoterType"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b93e096-4095-4fb2-bc1a-8d521921afdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bio import SeqIO\n",
    "from pathlib import Path\n",
    "\n",
    "cwd = Path.cwd()\n",
    "benchmark_path = cwd / \"Dataset\" / \"Benchmark_dataset\"\n",
    "independent_path = cwd / \"Dataset\" / \"Independent_test_dataset\"\n",
    "\n",
    "#Read Sequence file in fasta format using BioPython library \n",
    "    \n",
    "super_transform = {\"70\": PromoterType.SIGMA_70, \n",
    "                   \"54\": PromoterType.SIGMA_54, \n",
    "                   \"38\": PromoterType.SIGMA_38, \n",
    "                   \"32\": PromoterType.SIGMA_32, \n",
    "                   \"28\": PromoterType.SIGMA_28, \n",
    "                   \"24\": PromoterType.SIGMA_24                   \n",
    "                  }\n",
    "sequences = []\n",
    "labels = []\n",
    "for record in SeqIO.parse(independent_path / \"independent.txt\", \"fasta\"):\n",
    "    seq = str(record.seq)\n",
    "    label = super_transform[record.id]\n",
    "    sequences.append(seq)\n",
    "    labels.append(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffe98947-8c32-4f4f-b01b-a4b0c1be1c31",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d565a3f1-63e5-477d-9559-571a9448b2fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(benchmark_path / 'promoter_and_non-promoter' / 'positive2860.txt') as handle:\n",
    "    promoters = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'promoter_and_non-promoter' / 'negative2860.txt') as handle:\n",
    "    non_promoters = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma24promoter.txt') as handle:\n",
    "    sigma24promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma28promoter.txt') as handle:\n",
    "    sigma28promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma32promoter.txt') as handle:\n",
    "    sigma32promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma38promoter.txt') as handle:\n",
    "    sigma38promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma54promoter.txt') as handle:\n",
    "    sigma54promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "with open(benchmark_path / 'sigma_subtypes' / 'sigma70promoter.txt') as handle:\n",
    "    sigma70promoter = [str(record.seq) for record in SeqIO.parse(handle, \"fasta\")]\n",
    "\n",
    "# Promoter multiclass\n",
    "benchmark_dataset = sigma24promoter + sigma28promoter + sigma32promoter + sigma38promoter + sigma54promoter + sigma70promoter\n",
    "benchmark_labels = [PromoterType.SIGMA_24]*len(sigma24promoter) + [PromoterType.SIGMA_28]*len(sigma28promoter) + [PromoterType.SIGMA_32]*len(sigma32promoter) + [PromoterType.SIGMA_38]*len(sigma38promoter) + [PromoterType.SIGMA_54]*len(sigma54promoter) + [PromoterType.SIGMA_70]*len(sigma70promoter)\n",
    "benchmark_labels_ints = [_type.value - 2 for _type in benchmark_labels]\n",
    "benchmark_labels_one_hot = tf.one_hot(benchmark_labels_ints, 6)\n",
    "# Promoter binary (first stage)\n",
    "binary_dataset = promoters + non_promoters\n",
    "binary_labels_int = [1]*len(promoters) + [0]*len(non_promoters)\n",
    "binary_labels_one_hot = tf.one_hot(binary_labels_int, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9325045e-a2f3-44ec-aadb-b23e52cc778f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_seqs(data: List[str]) -> List[np.ndarray]:\n",
    "    ## Check Seqs Length\n",
    "    for i, seq in enumerate(data):   \n",
    "        if ( seq_len := len(seq) ) != 81:\n",
    "            raise ValueError(f\"Each sequence must have a length of 81nt.\\nSequence {i} has length {seq_len}nt\")\n",
    "\n",
    "    encoding = {'A':[1,0,0,0],'T':[0,1,0,0],'C':[0,0,1,0],'G':[0,0,0,1]}\n",
    "    return [np.array([[encoding[x] for x in seq.upper()] for seq in data])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b44a8901-f8a9-450e-8155-312c2d16b62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = {}\n",
    "current_order = \"hybrid\" # Just a name, it's used as a prefix when making the checkpoints' folders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cd5bac-4981-41db-b8f9-2a4ef2e27abe",
   "metadata": {},
   "source": [
    "### For One-Hot models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c4f1e8-1479-4671-8775-165ac4136e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data[current_order] = {\n",
    "    \"IsPromoter\":    {\"input\": preprocess_seqs(binary_dataset),    \"output\": binary_labels_one_hot.numpy()},\n",
    "    \"PromoterType\": {\"input\": preprocess_seqs(benchmark_dataset), \"output\": benchmark_labels_one_hot.numpy()}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8457f4-e053-4075-acd5-cd7849fe8791",
   "metadata": {},
   "source": [
    "## Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ee257d2-f42c-4f8f-b509-5873cf6fe851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import necessary layers  \n",
    "from tensorflow.keras.layers import Input, Conv1D, BatchNormalization\n",
    "from tensorflow.keras.layers import MaxPooling1D, Dropout, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import Model, regularizers\n",
    "\n",
    "from tensorflow_addons.optimizers import LazyAdam\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "\n",
    "models = [{\"name\": \"IsPromoter\", \"in_prefix\": \"\", \"out_classes\": 2},\n",
    "          {\"name\": \"PromoterType\", \"in_prefix\": \"\", \"out_classes\": 6}]\n",
    "\n",
    "def generate_model(name: str = \"Latest\", in_prefix: str = '', out_classes: int = 6):\n",
    "    # input\n",
    "    input_ = Input(shape =(81,4), name=in_prefix + 'mono_mer_in')\n",
    "\n",
    "    # 1st Conv Block\n",
    "    # Params for first Conv1D\n",
    "    hp_filters_1 = 128\n",
    "    hp_kernel_1 = 5\n",
    "    hp_kreg_1 = 1e-3\n",
    "    hp_breg_1 = 1e-2\n",
    "    # Params for second Conv1D\n",
    "    hp_filters_2 = 128\n",
    "    hp_kernel_2 = 9\n",
    "    hp_kreg_2 = 1e-3\n",
    "    hp_breg_2 = 1e-5\n",
    "    # Params for Dropout\n",
    "    hp_drop_1 = 0.45\n",
    "    \n",
    "    x = Conv1D (filters=hp_filters_1, kernel_size=hp_kernel_1, padding ='same', activation='relu', kernel_regularizer = regularizers.l2(hp_kreg_1), bias_regularizer = regularizers.l2(hp_breg_1))(input_)\n",
    "    x = Conv1D (filters=hp_filters_2, kernel_size=hp_kernel_2, padding ='same', activation='relu', kernel_regularizer = regularizers.l2(hp_kreg_2), bias_regularizer = regularizers.l2(hp_breg_2))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling1D(pool_size =2, strides =2, padding ='same')(x)\n",
    "    x = Dropout(rate=hp_drop_1)(x)\n",
    "\n",
    "    # Fully connected layers\n",
    "    x = Flatten()(x)\n",
    "    hp_units = 32\n",
    "    x = Dense(units=hp_units, activation ='relu', kernel_regularizer = regularizers.l2(1e-3), bias_regularizer = regularizers.l2(1e-3))(x)\n",
    "    output = Dense(units = out_classes, activation ='softmax')(x)\n",
    "\n",
    "    # Creating the model\n",
    "    model = Model (inputs=input_, outputs =output, name=name)\n",
    "    model.compile(optimizer=LazyAdam(), loss=tfa.losses.SigmoidFocalCrossEntropy(alpha=0.20, gamma=3, reduction=tf.keras.losses.Reduction.AUTO), metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35107194-5417-4491-aeda-c3d662e63c90",
   "metadata": {},
   "source": [
    "# Model Training - KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dc03bf-354c-435a-b5ab-9fb47cb8aa1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import pathlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4567ba0e-7866-4074-aea4-8492f986110c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "FOLDS = 5\n",
    "EPOCHS = 100\n",
    "VERBOSITY = 1\n",
    "BATCH_SIZE = None\n",
    "\n",
    "version_id = \"_1\"\n",
    "\n",
    "best_by_loss = []\n",
    "\n",
    "kfold = StratifiedKFold(n_splits=FOLDS, shuffle=True, random_state=0)\n",
    "\n",
    "early_stop_callback = tf.keras.callbacks.EarlyStopping(\n",
    "                                    monitor=\"val_loss\",\n",
    "                                    min_delta=0,\n",
    "                                    patience=15,\n",
    "                                    verbose=0,\n",
    "                                    mode=\"auto\",\n",
    "                                    restore_best_weights=True,\n",
    "                                )\n",
    "\n",
    "for current_model in models:\n",
    "    current_name = current_model[\"name\"]\n",
    "    inputs = training_data[current_order][current_name][\"input\"]\n",
    "    targets = training_data[current_order][current_name][\"output\"]\n",
    "\n",
    "    log_dir_base = pathlib.Path.cwd() / f\"logs_{current_order}{version_id}\"\n",
    "    checkpoint_dir_base = pathlib.Path.cwd() / f\"checkpoints_{current_order}{version_id}\"\n",
    "\n",
    "    # Save fold history for future plotting\n",
    "    fold_history = []\n",
    "\n",
    "    # Define per-fold score containers\n",
    "    acc_per_fold = []\n",
    "    loss_per_fold = []\n",
    "\n",
    "    # K-fold Cross Validation model evaluation\n",
    "    fold_no = 1\n",
    "    for train, test in kfold.split(np.zeros(len(targets)), targets.argmax(1)):\n",
    "\n",
    "        # Different path for each fold\n",
    "        fold_name = current_name + '_fold_' + str(fold_no)\n",
    "        log_dir = log_dir_base / fold_name\n",
    "        checkpoint_dir = checkpoint_dir_base / fold_name\n",
    "\n",
    "        # Make sure those paths exist\n",
    "        log_dir.mkdir(parents=True, exist_ok=True)\n",
    "        checkpoint_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "        # Callbacks for logging and model saving\n",
    "        logger_callback = tf.keras.callbacks.CSVLogger(log_dir / \"history.csv\", append=False)\n",
    "        model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=checkpoint_dir,\n",
    "            save_weights_only=False, \n",
    "            monitor='val_loss', \n",
    "            mode='min', \n",
    "            save_best_only=True)\n",
    "\n",
    "        # Define the model architecture\n",
    "        model = generate_model(**current_model)\n",
    "\n",
    "        # Print status\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'Training for fold {fold_no} ...')\n",
    "\n",
    "        # Fit data to model\n",
    "        history = model.fit([inputs[i][train] for i in range(len(inputs))][0], targets[train], # [0] added\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  epochs=EPOCHS, \n",
    "                  verbose=VERBOSITY, \n",
    "                  callbacks=[logger_callback, model_checkpoint_callback, early_stop_callback], \n",
    "                  validation_data=([inputs[i][test] for i in range(len(inputs))][0], targets[test])) # [0] added\n",
    "\n",
    "        fold_history.append(history)\n",
    "        \n",
    "        #print(\"Finished training fold!!!\")\n",
    "\n",
    "        # Load best checkpoint of the fold\n",
    "        model = load_model(checkpoint_dir)\n",
    "\n",
    "        # Generate generalization metrics\n",
    "        scores = model.evaluate([inputs[i][test] for i in range(len(inputs))][0], targets[test], verbose=0) # [0] added\n",
    "        print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
    "        acc_per_fold.append(scores[1] * 100)\n",
    "        loss_per_fold.append(scores[0])\n",
    "\n",
    "        # Increase fold number\n",
    "        fold_no = fold_no + 1\n",
    "\n",
    "        # Free resources\n",
    "        tf.keras.backend.clear_session()\n",
    "        \n",
    "    # == Provide average scores ==\n",
    "    print('\\n\\n\\n\\n')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print(f'Score per fold -- {current_name}')\n",
    "    for i in range(0, len(acc_per_fold)):\n",
    "        print('------------------------------------------------------------------------')\n",
    "        print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('Average scores for all folds:')\n",
    "    print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
    "    print(f'> Loss: {np.mean(loss_per_fold)}')\n",
    "    print('------------------------------------------------------------------------')\n",
    "    print('\\n\\n\\n\\n')\n",
    "\n",
    "    # For future loading\n",
    "    best_by_loss.append(np.argmin(loss_per_fold))\n",
    "print(best_by_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56f6a0ea-3de5-4917-a8d5-86893c9a92c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
